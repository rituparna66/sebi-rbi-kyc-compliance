# -*- coding: utf-8 -*-
"""complaince.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/rituparna66/01ab79bab2cace9e52cdae25747ff5d3/complaince.ipynb
"""

!pip install langchain langchain-community faiss-cpu sentence-transformers

import json
from langchain_core.documents import Document

with open(r"/content/documents_for_embedding.json", "r", encoding="utf-8") as f:
    data = json.load(f)

documents = [
    Document(
        page_content=item["content"],
        metadata=item["metadata"]
    )
    for item in data
]

len(documents)

from langchain_core.documents import Document

documents = []

for item in data:
    documents.append(
        Document(
            page_content=item["content"],
            metadata=item["metadata"] | {"id": item["id"]}
        )
    )

print(len(documents))

import os
os.environ["OPENAI_API_KEY"] = "OPEN_API_KEY"

!pip install langchain-openai
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small"
)

from langchain_community.vectorstores import FAISS

vectorstore = FAISS.from_documents(documents, embeddings)

vectorstore.save_local("compliance_faiss_index")

!pip install langchain langchain-openai faiss-cpu

import json
from langchain_core.documents import Document

with open("documents_for_embedding.json", "r", encoding="utf-8") as f:
    raw_docs = json.load(f)

documents = [
    Document(
        page_content=d["content"],
        metadata={**d["metadata"], "id": d["id"]}
    )
    for d in raw_docs
]

len(documents)

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

embeddings = OpenAIEmbeddings()

vectorstore = FAISS.from_documents(
    documents,
    embedding=embeddings
)

vectorstore.save_local("compliance_faiss_index")

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()

vectorstore = FAISS.load_local(
    "compliance_faiss_index",
    embeddings,
    allow_dangerous_deserialization=True
)

docs = vectorstore.similarity_search(
    "Can a broker accept unredacted Aadhaar?",
    k=3
)

for d in docs:
    print(d.page_content)

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS

embeddings = OpenAIEmbeddings()

vectorstore = FAISS.load_local(
    "compliance_faiss_index",
    embeddings,
    allow_dangerous_deserialization=True
)

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 6}
)

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0
)

from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate.from_template(
    """
You are a regulatory compliance assistant.
Answer ONLY using the context provided.
If the answer is not found, say: "Not found in regulations."

Context:
{context}

Question:
{question}
"""
)

from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from operator import itemgetter

rag_chain = (
    {
        "context": itemgetter("input") | retriever,
        "question": itemgetter("input")
    }
    | prompt
    | llm
    | StrOutputParser()
)

docs = retriever.invoke("Is Aadhaar mandatory for KYC?")
len(docs)

for d in docs:
    print(d.page_content)

!pip install langchain-openai
import os
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS

# Set the OpenAI API key (replace with your actual API key if running this cell in isolation)
os.environ["OPENAI_API_KEY"] = "OPENAI_API_KEY"

embeddings = OpenAIEmbeddings()

vectorstore = FAISS.load_local(
    "compliance_faiss_index",
    embeddings,
    allow_dangerous_deserialization=True
)

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 6}
)

docs = retriever.invoke(
    "Is Aadhaar mandatory for KYC?"
)

for d in docs:
    print(d.metadata["id"])
    print(d.page_content[:300])
    print("-"*50)

response = rag_chain.invoke({
    "input": "Is Aadhaar mandatory for KYC under Indian regulations?"
})

print(response)

from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
You are a regulatory compliance assistant.

Answer the question using ONLY the regulatory clauses below.
If the answer is not present, say: "Not found in regulations."

Regulatory clauses:
{context}

Question:
{question}

Answer:
"""
)

docs = retriever.invoke("Is Aadhaar mandatory for KYC?")

context = "\n".join([d.page_content for d in docs])

print("DEBUG CONTEXT ↓↓↓")
print(context)

prompt = f"""
Based on the provided regulations, answer the question: "Is Aadhaar mandatory for KYC?"

- Use the provided context ONLY.
- If the context provides a conditional answer, explain those conditions.
- If the information is truly missing, say: Not found in regulations.

Context:
{context}
"""

response = llm.invoke(prompt)
print(response.content)
